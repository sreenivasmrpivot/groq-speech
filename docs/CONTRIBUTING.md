# Groq Speech SDK - Contributing Guide

## ü§ù **Welcome Contributors!**

Thank you for your interest in contributing to the Groq Speech SDK! This guide will help you get started with development and ensure your contributions align with our project standards.

## üöÄ **Quick Start**

### **Prerequisites**
- Python 3.8+
- Node.js 18+
- Git
- Docker (optional, for testing)

### **Development Setup**
```bash
# Fork and clone the repository
git clone https://github.com/your-username/groq-speech.git
cd groq-speech

# Install Python dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Install frontend dependencies
cd examples/groq-speech-ui
npm install

# Configure environment
cp groq_speech/env.template groq_speech/.env
# Edit groq_speech/.env with your API keys
```

## üìã **Development Workflow**

### **1. Create a Feature Branch**
```bash
git checkout -b feature/your-feature-name
# or
git checkout -b fix/your-bug-fix
```

### **2. Make Your Changes**
- Follow the coding standards
- Add tests for new features
- Update documentation as needed

### **3. Test Your Changes**
```bash
# Run Python tests
python -m pytest tests/

# Run frontend tests
cd examples/groq-speech-ui
npm test

# Run integration tests
python examples/speech_demo.py --file test.wav
```

### **4. Commit Your Changes**
```bash
git add .
git commit -m "feat: add new feature description"
# or
git commit -m "fix: resolve issue description"
```

### **5. Push and Create Pull Request**
```bash
git push origin feature/your-feature-name
# Create PR on GitHub
```

## üéØ **Contribution Areas**

### **Core SDK (`groq_speech/`)**
- **Speech Recognition**: Improve accuracy and performance
- **Translation**: Add new language support
- **Diarization**: Enhance speaker detection
- **VAD**: Improve silence detection algorithms
- **Audio Processing**: Optimize format handling

### **API Server (`api/`)**
- **New Endpoints**: Add new API functionality
- **Performance**: Optimize response times
- **Error Handling**: Improve error responses
- **Monitoring**: Add health checks and metrics

### **Frontend (`examples/groq-speech-ui/`)**
- **UI Components**: Improve user interface
- **Audio Processing**: Enhance client-side processing
- **Performance**: Optimize rendering and processing
- **Accessibility**: Improve accessibility features

### **Documentation**
- **API Documentation**: Update API references
- **User Guides**: Improve user documentation
- **Code Comments**: Add inline documentation
- **Examples**: Create usage examples

## üìù **Coding Standards**

### **Python Code**
```python
# Use type hints
def process_audio(audio_data: np.ndarray, sample_rate: int) -> RecognitionResult:
    """Process audio data with comprehensive docstring.
    
    Args:
        audio_data: Audio data as numpy array
        sample_rate: Sample rate in Hz
        
    Returns:
        RecognitionResult: Processed recognition result
        
    Raises:
        AudioProcessingError: If audio processing fails
    """
    pass

# Use meaningful variable names
audio_level = calculate_rms(audio_data)
silence_threshold = 0.003

# Use constants for magic numbers
SILENCE_THRESHOLD = 0.003
REQUIRED_SILENCE_SECONDS = 15.0
```

### **TypeScript/React Code**
```typescript
// Use TypeScript interfaces
interface AudioRecorderConfig {
  sampleRate: number;
  chunkSize: number;
  onChunkProcessed: (audioData: Float32Array) => Promise<void>;
}

// Use meaningful function names
const processAudioChunk = async (audioData: Float32Array): Promise<void> => {
  // Implementation
};

// Use proper error handling
try {
  const result = await processAudio(audioData);
  return result;
} catch (error) {
  console.error('Audio processing failed:', error);
  throw new Error(`Audio processing failed: ${error.message}`);
}
```

### **Documentation**
```markdown
# Use clear headings
## Feature Name

### Description
Brief description of the feature.

### Usage
```python
# Code examples
result = process_audio(audio_data)
```

### Parameters
- `audio_data`: Description of parameter
- `sample_rate`: Description of parameter

### Returns
Description of return value
```

## üß™ **Testing Guidelines**

### **Python Tests**
```python
import pytest
from groq_speech.speech_recognizer import SpeechRecognizer
from groq_speech.speech_config import SpeechConfig

class TestSpeechRecognizer:
    def test_audio_processing(self):
        """Test audio processing functionality."""
        config = SpeechConfig()
        recognizer = SpeechRecognizer(config)
        
        # Test with sample audio data
        audio_data = np.array([0.1, 0.2, 0.3])
        result = recognizer.process_audio(audio_data, 16000)
        
        assert result is not None
        assert hasattr(result, 'text')
    
    def test_error_handling(self):
        """Test error handling."""
        config = SpeechConfig()
        recognizer = SpeechRecognizer(config)
        
        with pytest.raises(AudioProcessingError):
            recognizer.process_audio(None, 16000)
```

### **Frontend Tests**
```typescript
import { render, screen } from '@testing-library/react';
import { AudioRecorder } from '@/lib/audio-recorder';

describe('AudioRecorder', () => {
  it('should initialize correctly', () => {
    const recorder = new AudioRecorder({
      sampleRate: 16000,
      chunkSize: 8192,
      onChunkProcessed: jest.fn(),
      onVisualUpdate: jest.fn(),
      onError: jest.fn()
    });
    
    expect(recorder).toBeDefined();
  });
  
  it('should handle audio processing', async () => {
    const mockCallback = jest.fn();
    const recorder = new AudioRecorder({
      sampleRate: 16000,
      chunkSize: 8192,
      onChunkProcessed: mockCallback,
      onVisualUpdate: jest.fn(),
      onError: jest.fn()
    });
    
    // Test audio processing
    await recorder.processAudio(sampleAudioData);
    
    expect(mockCallback).toHaveBeenCalled();
  });
});
```

### **Integration Tests**
```python
async def test_file_transcription():
    """Test complete file transcription flow."""
    recognizer = SpeechRecognizer(SpeechConfig())
    
    # Test with actual audio file
    result = await recognizer.process_file('test.wav', enable_diarization=False)
    
    assert result is not None
    assert hasattr(result, 'text')
    assert len(result.text) > 0
```

## üîç **Code Review Process**

### **Before Submitting**
- [ ] Code follows project standards
- [ ] Tests are included and passing
- [ ] Documentation is updated
- [ ] No console.log statements in production code
- [ ] Error handling is comprehensive
- [ ] Performance is acceptable

### **Review Checklist**
- [ ] Code is readable and well-documented
- [ ] Tests cover new functionality
- [ ] No breaking changes (unless intentional)
- [ ] Performance impact is acceptable
- [ ] Security considerations are addressed
- [ ] Documentation is updated

## üêõ **Bug Reports**

### **Bug Report Template**
```markdown
## Bug Description
Brief description of the bug.

## Steps to Reproduce
1. Step 1
2. Step 2
3. Step 3

## Expected Behavior
What should happen.

## Actual Behavior
What actually happens.

## Environment
- OS: [e.g., macOS 13.0]
- Python: [e.g., 3.9.0]
- Node.js: [e.g., 18.0.0]
- Browser: [e.g., Chrome 120.0]

## Additional Context
Any additional information that might be helpful.
```

## ‚ú® **Feature Requests**

### **Feature Request Template**
```markdown
## Feature Description
Brief description of the feature.

## Use Case
Why is this feature needed?

## Proposed Solution
How should this feature work?

## Alternatives Considered
What other approaches were considered?

## Additional Context
Any additional information that might be helpful.
```

## üöÄ **Release Process**

### **Version Numbering**
- **Major** (1.0.0): Breaking changes
- **Minor** (1.1.0): New features, backward compatible
- **Patch** (1.0.1): Bug fixes, backward compatible

### **Release Checklist**
- [ ] All tests are passing
- [ ] Documentation is updated
- [ ] Changelog is updated
- [ ] Version numbers are updated
- [ ] Release notes are written

## üìö **Resources**

### **Documentation**
- [Architecture Guide](ARCHITECTURE.md)
- [API Reference](../groq_speech/API_REFERENCE.md)
- [Code Analysis](CODE_ANALYSIS.md)
- [Deployment Guide](../deployment/README.md)

### **External Resources**
- [Groq API Documentation](https://console.groq.com/docs)
- [Pyannote.audio Documentation](https://github.com/pyannote/pyannote-audio)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Next.js Documentation](https://nextjs.org/docs)

## ü§ù **Community Guidelines**

### **Code of Conduct**
- Be respectful and inclusive
- Focus on constructive feedback
- Help others learn and grow
- Follow the golden rule

### **Communication**
- Use clear and concise language
- Provide context for questions
- Be patient with newcomers
- Celebrate contributions

## üìû **Getting Help**

### **Questions and Support**
- **GitHub Issues**: For bug reports and feature requests
- **Discussions**: For general questions and ideas
- **Pull Requests**: For code contributions
- **Documentation**: For usage questions

### **Development Help**
- **Code Review**: Ask for help with code reviews
- **Testing**: Get help with test cases
- **Documentation**: Get help with documentation
- **Architecture**: Get help with design decisions

## üéâ **Recognition**

### **Contributor Recognition**
- Contributors are listed in the README
- Significant contributions are highlighted
- Regular contributors may be invited as maintainers
- All contributions are appreciated and valued

### **Types of Contributions**
- **Code**: Bug fixes, new features, improvements
- **Documentation**: Guides, examples, API references
- **Testing**: Test cases, bug reports, quality assurance
- **Community**: Helping others, answering questions

---

**Thank you for contributing to the Groq Speech SDK! Together, we can build amazing speech processing tools.**